{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://172.20.43.125:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[3]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[3] appName=PySparkShell>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting infant survival"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the csv file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalBirthsPath = './data/births_final.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "births_final = spark.read.csv(finalBirthsPath, sep = ',', header = True, inferSchema = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+----------------+-------------------+---------+----------------+-----------------+------------+-------------+------------+-------------+------------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+\n",
      "|INFANT_ALIVE_AT_REPORT|MOTHER_AGE_YEARS|FATHER_COMBINED_AGE|CIG_1_TRI|MOTHER_HEIGHT_IN|MOTHER_PRE_WEIGHT|DIABETES_PRE|DIABETES_GEST|HYP_TENS_PRE|HYP_TENS_GEST|PREV_BIRTH_PRETERM|BIRTH_PLACE_6|BIRTH_PLACE_3|BIRTH_PLACE_5|BIRTH_PLACE_9|BIRTH_PLACE_4|BIRTH_PLACE_7|BIRTH_PLACE_2|\n",
      "+----------------------+----------------+-------------------+---------+----------------+-----------------+------------+-------------+------------+-------------+------------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+\n",
      "|                     0|              29|                 99|        0|              99|              999|           0|            0|           0|            0|                 0|            0|            0|            0|            0|            0|            0|            0|\n",
      "|                     0|              22|                 29|        0|              65|              180|           0|            0|           0|            0|                 0|            0|            0|            0|            0|            0|            0|            0|\n",
      "|                     0|              38|                 40|        0|              63|              155|           0|            0|           0|            0|                 0|            0|            0|            0|            0|            0|            0|            0|\n",
      "|                     0|              39|                 42|        0|              60|              128|           0|            0|           0|            0|                 1|            0|            0|            0|            0|            0|            0|            0|\n",
      "|                     0|              18|                 99|        4|              61|              110|           0|            0|           0|            0|                 0|            0|            0|            0|            0|            0|            0|            0|\n",
      "+----------------------+----------------+-------------------+---------+----------------+-----------------+------------+-------------+------------+-------------+------------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "births_final.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- INFANT_ALIVE_AT_REPORT: integer (nullable = true)\n",
      " |-- MOTHER_AGE_YEARS: integer (nullable = true)\n",
      " |-- FATHER_COMBINED_AGE: integer (nullable = true)\n",
      " |-- CIG_1_TRI: integer (nullable = true)\n",
      " |-- MOTHER_HEIGHT_IN: integer (nullable = true)\n",
      " |-- MOTHER_PRE_WEIGHT: integer (nullable = true)\n",
      " |-- DIABETES_PRE: integer (nullable = true)\n",
      " |-- DIABETES_GEST: integer (nullable = true)\n",
      " |-- HYP_TENS_PRE: integer (nullable = true)\n",
      " |-- HYP_TENS_GEST: integer (nullable = true)\n",
      " |-- PREV_BIRTH_PRETERM: integer (nullable = true)\n",
      " |-- BIRTH_PLACE_6: integer (nullable = true)\n",
      " |-- BIRTH_PLACE_3: integer (nullable = true)\n",
      " |-- BIRTH_PLACE_5: integer (nullable = true)\n",
      " |-- BIRTH_PLACE_9: integer (nullable = true)\n",
      " |-- BIRTH_PLACE_4: integer (nullable = true)\n",
      " |-- BIRTH_PLACE_7: integer (nullable = true)\n",
      " |-- BIRTH_PLACE_2: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "births_final.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dense Vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.mllib.linalg as ln\n",
    "import pyspark.mllib.feature as ft\n",
    "import pyspark.mllib.regression as reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the `input_data` \n",
    "births_final = births_final.rdd.map(lambda x: reg.LabeledPoint(x[0], ln.Vectors.dense(x[1:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting into training and test sets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Training set: 70%;\n",
    "- Test set: 30%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "births_train, births_test = births_final.randomSplit([0.7, 0.3], seed = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Infant Survival\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " In this section, we will build two models: a linear classifier — the logistic regression, and a non-linear one— a random forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Logistic regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.classification\\\n",
    "    import LogisticRegressionWithLBFGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_Model = LogisticRegressionWithLBFGS \\\n",
    " .train(births_train, iterations=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having trained the model using the births_train dataset, let's use the model to\n",
    "predict the classes for our testing set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_results = (\n",
    " births_test.map(lambda row: row.label) \\\n",
    " .zip(LR_Model \\\n",
    " .predict(births_test\\\n",
    " .map(lambda row: row.features)))\n",
    " ).map(lambda row: (row[0], row[1] * 1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preceding snippet creates an RDD where each element is a tuple, with the first\n",
    "element being the actual label and the second one, the model's prediction.\n",
    "\n",
    "MLlib provides an evaluation metric for classification and regression. Let's check\n",
    "how well or how bad our model performed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0, 1.0), (0.0, 0.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_results.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.mllib.evaluation as ev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_evaluation = ev.BinaryClassificationMetrics(LR_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under PR: 0.79\n",
      "Area under ROC: 0.62\n"
     ]
    }
   ],
   "source": [
    "print('Area under PR: {0:.2f}'\\\n",
    "      .format(LR_evaluation.areaUnderPR))\n",
    "print('Area under ROC: {0:.2f}'\\\n",
    "     .format(LR_evaluation.areaUnderROC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other evaluation metrics (After creating a Pandas DataFrame):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_results = pd.DataFrame(LR_results.collect(),\\\n",
    "             columns=['y_test', 'y_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy, F1-score, Classification report and Confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.6091277143908723\n",
      "F1 score: 0.6797732481003499\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.40      0.50      6635\n",
      "         1.0       0.59      0.81      0.68      6950\n",
      "\n",
      "   micro avg       0.61      0.61      0.61     13585\n",
      "   macro avg       0.63      0.60      0.59     13585\n",
      "weighted avg       0.63      0.61      0.59     13585\n",
      "\n",
      "Confusion matrix:\n",
      "[[2639 3996]\n",
      " [1314 5636]]\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy score: {}\\nF1 score: {}\\n\\n'\\\n",
    "      .format(accuracy_score(y_results['y_test'], y_results['y_pred']),\n",
    "             f1_score(y_results['y_test'], y_results['y_pred'])))\n",
    "print(classification_report(y_results['y_test'],\\\n",
    "                            y_results['y_pred']))\n",
    "print('Confusion matrix:')\n",
    "print(confusion_matrix(y_results['y_test'],\\\n",
    "                            y_results['y_pred']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Random Forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.tree import RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_model = RandomForest\\\n",
    "    .trainClassifier(data=births_train,\n",
    "                    numClasses=2,\n",
    "                    categoricalFeaturesInfo={},\n",
    "                    numTrees=5,\n",
    "                    featureSubsetStrategy='all',\n",
    "                    seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_results = (\n",
    "    births_test.map(lambda row: row.label) \\\n",
    "    .zip(RF_model \\\n",
    "    .predict(births_test\\\n",
    "    .map(lambda row: row.features)))\n",
    "    ).map(lambda row: (row[0], row[1] * 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_evaluation = ev.BinaryClassificationMetrics(RF_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under PR: 0.77\n",
      "Area under ROC: 0.61\n"
     ]
    }
   ],
   "source": [
    "print('Area under PR: {0:.2f}' \\\n",
    " .format(RF_evaluation.areaUnderPR))\n",
    "print('Area under ROC: {0:.2f}' \\\n",
    " .format(RF_evaluation.areaUnderROC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other metrics (<i>sklearn</i>):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_results_rf = pd.DataFrame(RF_results.collect(),\\\n",
    "             columns=['y_test', 'y_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.5964666912035334\n",
      "F1 score: 0.6574606348412897\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.41      0.51      6929\n",
      "         1.0       0.56      0.79      0.66      6656\n",
      "\n",
      "   micro avg       0.60      0.60      0.60     13585\n",
      "   macro avg       0.62      0.60      0.58     13585\n",
      "weighted avg       0.62      0.60      0.58     13585\n",
      "\n",
      "Confusion matrix:\n",
      "[[2842 4087]\n",
      " [1395 5261]]\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy score: {}\\nF1 score: {}\\n\\n'\\\n",
    "      .format(accuracy_score(y_results_rf['y_test'], y_results_rf['y_pred']),\n",
    "             f1_score(y_results_rf['y_test'], y_results_rf['y_pred'])))\n",
    "print(classification_report(y_results_rf['y_test'],\\\n",
    "                            y_results_rf['y_pred']))\n",
    "print('Confusion matrix:')\n",
    "print(confusion_matrix(y_results_rf['y_test'],\\\n",
    "                            y_results_rf['y_pred']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
