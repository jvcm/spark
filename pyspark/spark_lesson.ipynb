{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import extractInformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://172.20.43.125:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[3]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[3] appName=PySparkShell>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Parallelize data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sc.parallelize(\n",
    "[('Amber', 22), ('Alfred', 23), ('Skye', 4), \n",
    "('Albert', 12), ('Amber', 9), ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Amber', 22), ('Alfred', 23), ('Skye', 4), ('Albert', 12), ('Amber', 9)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- External or local file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['                   1                                          2101  M1087 432311  4M4                2014U7CN                                    I64 238 070   24 0111I64                                                                                                                                                                           01 I64                                                                                                  01  11                                 100 601',\n",
       " '                   1                                          2101  M1058 371708  4D3                2014U7CN                                    I250214 062   21 0311I250 61I272 62E669                                                                                                                                                            03 I250 E669 I272                                                                                       01  11                                 100 601']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_from_file = sc.textFile('./data/VS14MORT.txt')\n",
    "data_from_file.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Resilient Distributed Dataset (RDD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resilient Distributed Datasets (RDDs) are a distributed collection of immutable JVM\n",
    "objects that allow you to perform calculations very quickly, and they are the backbone\n",
    "of Apache Spark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_from_file_conv = data_from_file.map(extractInformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['1', '  ', '2', '1', '01', 'M', '1', '087', ' ', '43', '23', '11',\n",
       "        '  ', '4', 'M', '4', '2014', 'U', '7', 'C', 'N', ' ', ' ', 'I64 ',\n",
       "        '238', '070', '   ', '24', '01', '11I64  ', '       ', '       ',\n",
       "        '       ', '       ', '       ', '       ', '       ', '       ',\n",
       "        '       ', '       ', '       ', '       ', '       ', '       ',\n",
       "        '       ', '       ', '       ', '       ', '       ', '01',\n",
       "        'I64  ', '     ', '     ', '     ', '     ', '     ', '     ',\n",
       "        '     ', '     ', '     ', '     ', '     ', '     ', '     ',\n",
       "        '     ', '     ', '     ', '     ', '     ', '     ', '01', ' ',\n",
       "        ' ', '1', '1', '100', '6'], dtype='<U40')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_from_file_conv.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New dataset (Year of death into numeric value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2014 = data_from_file_conv.map(lambda row: int(row[16]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2014, 2014, 2014, 2014, 2014]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2014.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More columns need to use tuples, dicts or lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2014_2 = data_from_file_conv.map(\n",
    "    lambda row: (row[16], int(row[16])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2014', 2014),\n",
       " ('2014', 2014),\n",
       " ('2014', 2014),\n",
       " ('2014', 2014),\n",
       " ('2014', 2014)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2014_2.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filtered = data_from_file_conv.filter(\n",
    "    lambda row: (row[16] == '2014' and row[21] == '0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_filtered.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flat Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2014_flat = data_from_file_conv.flatMap(\n",
    "    lambda row: (row[16], int(row[16]) + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2014', 2015, '2014', 2015, '2014', 2015, '2014', 2015, '2014', 2015]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2014_flat.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct_gender = data_from_file_conv.map(\n",
    "    lambda row: row[5]).distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-99', 'M', 'F']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distinct_gender.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraction = 0.1\n",
    "data_sample = data_from_file_conv.sample(\n",
    "    withReplacement=False,\n",
    "    fraction=fraction,\n",
    "    seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset: 2631171, sample: 262402\n"
     ]
    }
   ],
   "source": [
    "print('Original dataset: {0}, sample: {1}'.format(\n",
    "    data_from_file_conv.count(), data_sample.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Left outer join:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd1 = sc.parallelize(\n",
    "    [('a', 1), ('b', 4), ('c', 10),])\n",
    "rdd2 = sc.parallelize(\n",
    "    [('a', 4), ('a', 1), ('b', '6'), ('d', 15)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd3 = rdd1.leftOuterJoin(rdd2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('c', (10, None)), ('b', (4, '6')), ('a', (1, 4)), ('a', (1, 1))]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd3.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Inner join:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd4 = rdd1.join(rdd2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('b', (4, '6')), ('a', (1, 4)), ('a', (1, 1))]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd4.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Intersection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd5 = rdd1.intersection(rdd2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 1)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd5.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- take(n): return n top rows from a single data partition;\n",
    "- takeSample(withReplacement, n, seed): take n random records;\n",
    "- count(): counts the number of elements in the RDD;\n",
    "- countByKey(): get the counts of distinct keys, if the dataset is in a key-value form;\n",
    "- collect(): returns all the elements of the RDD to the driver."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1.map(lambda row: row[1]).reduce(lambda x,y: x + y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reduceByKey() works in a similar wai, but it performs a reduction on a key-by-key basis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('b', 4), ('c', 2), ('a', 12), ('d', 5)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_key = sc.parallelize(\n",
    " [('a', 4),('b', 3),('c', 2),('a', 8),('d', 2),('b', 1),\n",
    " ('d', 3)],4)\n",
    "data_key.reduceByKey(lambda x, y: x + y).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save as text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import parseInput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_key.saveAsTextFile(\n",
    "    './data/data_key.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_key_read = sc.textFile('./data/data_key.txt').\\\n",
    "    map(parseInput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 4), ('a', 8), ('d', 2), ('b', 3), ('c', 2), ('b', 1), ('d', 3)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_key_read.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For each"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applies same function to each element in RDD in an iterative way. It is useful when you want to save the data to a database that is not natively supported by PySpark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLI will show each RDD line printed\n",
    "data_key.foreach(print)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A DataFrame is an immutable distributed collection of data that is organized into\n",
    "named columns analogous to a table in a relational database. \n",
    "\n",
    "Spark DataFrame is a similar\n",
    "concept of <i>Pandas DataFrame</i>, in that it allows users to easily work with structured data (for example, data\n",
    "tables)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "stringJSONRDD = sc.parallelize((\"\"\"\n",
    "     { \"id\": \"123\",\n",
    "    \"name\": \"Katie\",\n",
    "    \"age\": 19,\n",
    "    \"eyeColor\": \"brown\"\n",
    "     }\"\"\",\n",
    "    \"\"\"{\n",
    "    \"id\": \"234\",\n",
    "    \"name\": \"Michael\",\n",
    "    \"age\": 22,\n",
    "    \"eyeColor\": \"green\"\n",
    "     }\"\"\",\n",
    "    \"\"\"{\n",
    "    \"id\": \"345\",\n",
    "    \"name\": \"Simone\",\n",
    "    \"age\": 23,\n",
    "    \"eyeColor\": \"blue\"\n",
    "     }\"\"\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "swimmersJSON = spark.read.json(stringJSONRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(age=19, eyeColor='brown', id='123', name='Katie'),\n",
       " Row(age=22, eyeColor='green', id='234', name='Michael'),\n",
       " Row(age=23, eyeColor='blue', id='345', name='Simone')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swimmersJSON.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a temporary table\n",
    "swimmersJSON.createOrReplaceTempView('swimmersJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframe API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---+-------+\n",
      "|age|eyeColor| id|   name|\n",
      "+---+--------+---+-------+\n",
      "| 19|   brown|123|  Katie|\n",
      "| 22|   green|234|Michael|\n",
      "| 23|    blue|345| Simone|\n",
      "+---+--------+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "swimmersJSON.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SQL query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(age=19, eyeColor='brown', id='123', name='Katie'),\n",
       " Row(age=22, eyeColor='green', id='234', name='Michael'),\n",
       " Row(age=23, eyeColor='blue', id='345', name='Simone')]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql('select * from swimmersJSON').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: long (nullable = true)\n",
      " |-- eyeColor: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the schema\n",
    "swimmersJSON.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Programatically specifying the schema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data types\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comma delimited data\n",
    "stringCSVRDD = sc.parallelize([\n",
    "    (123, 'Katie', 19, 'brown'),\n",
    "    (234, 'Michael', 22, 'green'),\n",
    "    (345, 'Simone', 23, 'blue')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify schema\n",
    "schema = StructType([\n",
    "    StructField(name = 'id', dataType = LongType(), nullable = True),\n",
    "    StructField('name', StringType(), True),\n",
    "    StructField('age', LongType(), True),\n",
    "    StructField('eyeColor', StringType(), True),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the schema to the RDD and Create DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "swimmers = spark.createDataFrame(stringCSVRDD, schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates a temporary view using the DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "swimmers.createOrReplaceTempView('swimmers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: long (nullable = true)\n",
      " |-- eyeColor: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "swimmers.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying with the DataFrame API:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swimmers.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running filter statements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---+--------+\n",
      "| id|   name|age|eyeColor|\n",
      "+---+-------+---+--------+\n",
      "|234|Michael| 22|   green|\n",
      "+---+-------+---+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ID and age where age = 22\n",
    "swimmers.select('*').filter('age == 22').show()\n",
    "\n",
    "# another way to write the above query is below\n",
    "# swimmers.select(swimmers.id, swimmers.age)\\\n",
    "#    .filter(swimmers.age == 22).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+\n",
      "|  name|eyeColor|\n",
      "+------+--------+\n",
      "| Katie|   brown|\n",
      "|Simone|    blue|\n",
      "+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Swimmers who have an eye color that begins with 'b'\n",
    "swimmers.select('name', 'eyeColor')\\\n",
    "    .filter(\"eyeColor like 'b%'\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying with SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|       3|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select count(1) from swimmers').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter statements with <i>where</i>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "| id|age|\n",
      "+---+---+\n",
      "|234| 22|\n",
      "+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select id,age from swimmers where age = 22').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+\n",
      "|  name|eyeColor|\n",
      "+------+--------+\n",
      "| Katie|   brown|\n",
      "|Simone|    blue|\n",
      "+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "\"select name,eyeColor from swimmers where eyeColor like 'b%'\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame scenario – on-time flight performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set file paths\n",
    "flightPerfFilePath = \"./data/departuredelays.csv\"\n",
    "airportsFilePath = \"./data/airport-codes-na.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports = spark.read.csv(airportsFilePath,\n",
    "                         header = True,\n",
    "                         inferSchema = True,\n",
    "                         sep = '\\t')\n",
    "flightPerf = spark.read.csv(flightPerfFilePath,\n",
    "                           header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports.createOrReplaceTempView('airports')\n",
    "flightPerf.createOrReplaceTempView('flightPerformance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[date: string, delay: string, distance: string, origin: string, destination: string]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cache the Departure Delays dataset\n",
    "flightPerf.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-------+----+\n",
      "|      City|State|Country|IATA|\n",
      "+----------+-----+-------+----+\n",
      "|Abbotsford|   BC| Canada| YXX|\n",
      "|  Aberdeen|   SD|    USA| ABR|\n",
      "|   Abilene|   TX|    USA| ABI|\n",
      "|     Akron|   OH|    USA| CAK|\n",
      "|   Alamosa|   CO|    USA| ALS|\n",
      "+----------+-----+-------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airports.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+--------+------+-----------+\n",
      "|    date|delay|distance|origin|destination|\n",
      "+--------+-----+--------+------+-----------+\n",
      "|01011245|    6|     602|   ABE|        ATL|\n",
      "|01020600|   -8|     369|   ABE|        DTW|\n",
      "|01021245|   -2|     602|   ABE|        ATL|\n",
      "|01020605|   -4|     602|   ABE|        ATL|\n",
      "|01031245|   -4|     602|   ABE|        ATL|\n",
      "+--------+-----+--------+------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flightPerf.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Joining flight performance and airports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+--------+\n",
      "|   City|origin|  Delays|\n",
      "+-------+------+--------+\n",
      "|Seattle|   SEA|159086.0|\n",
      "|Spokane|   GEG| 12404.0|\n",
      "|  Pasco|   PSC|   949.0|\n",
      "+-------+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query Sum of Flight Delays by City and Origin Code\n",
    "# (for Washington State)\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "select a.City, f.origin, sum(f.delay) as Delays\n",
    "from flightPerformance f join airports a\n",
    "on a.IATA = f.origin\n",
    "where a.State = 'WA'\n",
    "group by a.City, f.origin\n",
    "order by sum(f.delay) desc\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing flight-performance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+\n",
      "|State|   Delays|\n",
      "+-----+---------+\n",
      "|   SC|  80666.0|\n",
      "|   AZ| 401793.0|\n",
      "|   LA| 199136.0|\n",
      "|   MN| 256811.0|\n",
      "|   NJ| 452791.0|\n",
      "|   OR| 109333.0|\n",
      "|   VA|  98016.0|\n",
      "| null| 397237.0|\n",
      "|   RI|  30760.0|\n",
      "|   WY|  15365.0|\n",
      "|   KY|  61156.0|\n",
      "|   NH|  20474.0|\n",
      "|   MI| 366486.0|\n",
      "|   NV| 474208.0|\n",
      "|   WI| 152311.0|\n",
      "|   ID|  22932.0|\n",
      "|   CA|1891919.0|\n",
      "|   CT|  54662.0|\n",
      "|   NE|  59376.0|\n",
      "|   MT|  19271.0|\n",
      "+-----+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "select a.State, sum(f.delay) as Delays\n",
    "from flightPerformance f join airports a\n",
    "on a.IATA = f.origin\n",
    "where a.Country = 'USA'\n",
    "group by a.State\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_delays_pd = spark.sql(\"\"\"\n",
    "select a.State, sum(f.delay) as Delays\n",
    "from flightPerformance f join airports a\n",
    "on a.IATA = f.origin\n",
    "where a.Country = 'USA'\n",
    "group by a.State\n",
    "\"\"\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jvcm/tsenv/lib/python3.6/site-packages/pandas/core/indexing.py:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "states_delays_pd['State'].loc[states_delays_pd['State'].isnull()] = ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Delays</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SC</td>\n",
       "      <td>80666.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AZ</td>\n",
       "      <td>401793.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LA</td>\n",
       "      <td>199136.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MN</td>\n",
       "      <td>256811.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NJ</td>\n",
       "      <td>452791.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  State    Delays\n",
       "0    SC   80666.0\n",
       "1    AZ  401793.0\n",
       "2    LA  199136.0\n",
       "3    MN  256811.0\n",
       "4    NJ  452791.0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states_delays_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 50 artists>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,8))\n",
    "plt.bar(states_delays_pd['State'], states_delays_pd['Delays'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Prepare Data for Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame([\n",
    " (1, 144.5, 5.9, 33, 'M'),\n",
    " (2, 167.2, 5.4, 45, 'M'),\n",
    " (3, 124.1, 5.2, 23, 'F'),\n",
    " (4, 144.5, 5.9, 33, 'M'),\n",
    " (5, 133.2, 5.7, 54, 'F'),\n",
    " (3, 124.1, 5.2, 23, 'F'),\n",
    " (5, 129.2, 5.3, 42, 'M'),\n",
    " ], schema= ['id', 'weight', 'height', 'age', 'gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+---+------+\n",
      "| id|weight|height|age|gender|\n",
      "+---+------+------+---+------+\n",
      "|  1| 144.5|   5.9| 33|     M|\n",
      "|  2| 167.2|   5.4| 45|     M|\n",
      "|  3| 124.1|   5.2| 23|     F|\n",
      "|  4| 144.5|   5.9| 33|     M|\n",
      "|  5| 133.2|   5.7| 54|     F|\n",
      "|  3| 124.1|   5.2| 23|     F|\n",
      "|  5| 129.2|   5.3| 42|     M|\n",
      "+---+------+------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check pure duplicates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of rows: 7\n",
      "Count of distinct rows: 6\n"
     ]
    }
   ],
   "source": [
    "print('Count of rows: {0}'.format(df.count()))\n",
    "print('Count of distinct rows: {0}'.format(df.distinct().count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+---+------+\n",
      "| id|weight|height|age|gender|\n",
      "+---+------+------+---+------+\n",
      "|  5| 133.2|   5.7| 54|     F|\n",
      "|  5| 129.2|   5.3| 42|     M|\n",
      "|  1| 144.5|   5.9| 33|     M|\n",
      "|  4| 144.5|   5.9| 33|     M|\n",
      "|  2| 167.2|   5.4| 45|     M|\n",
      "|  3| 124.1|   5.2| 23|     F|\n",
      "+---+------+------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check duplicates (other than ID):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts of IDs: 6\n",
      "Counts of distinct IDs: 5\n"
     ]
    }
   ],
   "source": [
    "print('Counts of IDs: {0}'.format(df.count()))\n",
    "print('Counts of distinct IDs: {0}'.format(\n",
    "    df.select([\n",
    "        c for c in df.columns if c != 'id'\n",
    "    ]).distinct().count()\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropDuplicates(\n",
    "    subset= [c for c in df.columns if c != 'id']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+---+------+\n",
      "| id|weight|height|age|gender|\n",
      "+---+------+------+---+------+\n",
      "|  5| 133.2|   5.7| 54|     F|\n",
      "|  1| 144.5|   5.9| 33|     M|\n",
      "|  2| 167.2|   5.4| 45|     M|\n",
      "|  3| 124.1|   5.2| 23|     F|\n",
      "|  5| 129.2|   5.3| 42|     M|\n",
      "+---+------+------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duplicated IDs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+\n",
      "|count|distinct|\n",
      "+-----+--------+\n",
      "|    5|       4|\n",
      "+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.agg(\n",
    "    fn.count('id').alias('count'),\n",
    "    fn.countDistinct('id').alias('distinct')\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have\n",
    "already dropped all the duplicates, we can safely assume that this might just be a\n",
    "fluke in our ID data, so we will give each row a unique ID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+---+------+-------------+\n",
      "| id|weight|height|age|gender|       new_id|\n",
      "+---+------+------+---+------+-------------+\n",
      "|  5| 133.2|   5.7| 54|     F|  25769803776|\n",
      "|  1| 144.5|   5.9| 33|     M| 171798691840|\n",
      "|  2| 167.2|   5.4| 45|     M| 592705486848|\n",
      "|  3| 124.1|   5.2| 23|     F|1236950581248|\n",
      "|  5| 129.2|   5.3| 42|     M|1365799600128|\n",
      "+---+------+------+---+------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn('new_id', \n",
    "              fn.monotonically_increasing_id()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('id', \n",
    "              fn.monotonically_increasing_id())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If your data is a discrete Boolean, you can turn it into a categorical variable by adding a third category — Missing\n",
    "- If your data is already categorical, you can simply extend the number of levels and add the Missing category as well\n",
    "- If you're dealing with ordinal or numerical data, you can impute either mean, median, or some other predefined value (for example, first or third quartile, depending on the distribution shape of your data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_miss = spark.createDataFrame([\n",
    " (1, 143.5, 5.6, 28, 'M', 100000),\n",
    " (2, 167.2, 5.4, 45, 'M', None),\n",
    " (3, None , 5.2, None, None, None),\n",
    " (4, 144.5, 5.9, 33, 'M', None),\n",
    " (5, 133.2, 5.7, 54, 'F', None),\n",
    " (6, 124.1, 5.2, None, 'F', None),\n",
    " (7, 129.2, 5.3, 42, 'M', 76000),\n",
    " ], ['id', 'weight', 'height', 'age', 'gender', 'income'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+----+------+------+\n",
      "| id|weight|height| age|gender|income|\n",
      "+---+------+------+----+------+------+\n",
      "|  1| 143.5|   5.6|  28|     M|100000|\n",
      "|  2| 167.2|   5.4|  45|     M|  null|\n",
      "|  3|  null|   5.2|null|  null|  null|\n",
      "|  4| 144.5|   5.9|  33|     M|  null|\n",
      "|  5| 133.2|   5.7|  54|     F|  null|\n",
      "|  6| 124.1|   5.2|null|     F|  null|\n",
      "|  7| 129.2|   5.3|  42|     M| 76000|\n",
      "+---+------+------+----+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_miss.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the frequency of missing values by column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+--------------+------------------+------------------+------------------+\n",
      "|id_missing|    weight_missing|height_missing|       age_missing|    gender_missing|    income_missing|\n",
      "+----------+------------------+--------------+------------------+------------------+------------------+\n",
      "|       0.0|0.1428571428571429|           0.0|0.2857142857142857|0.1428571428571429|0.7142857142857143|\n",
      "+----------+------------------+--------------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_miss.agg(*[\n",
    "    (1 - (fn.count(c)/fn.count('*'))).alias(c + '_missing')\n",
    "    for c in df_miss.columns\n",
    "]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove columns with more than 50% of missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_miss_no_income = df_miss.select([\n",
    "    c for c in df_miss.columns if c != 'income' \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+----+------+\n",
      "| id|weight|height| age|gender|\n",
      "+---+------+------+----+------+\n",
      "|  1| 143.5|   5.6|  28|     M|\n",
      "|  2| 167.2|   5.4|  45|     M|\n",
      "|  3|  null|   5.2|null|  null|\n",
      "|  4| 144.5|   5.9|  33|     M|\n",
      "|  5| 133.2|   5.7|  54|     F|\n",
      "|  6| 124.1|   5.2|null|     F|\n",
      "|  7| 129.2|   5.3|  42|     M|\n",
      "+---+------+------+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_miss_no_income.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the frequency of missing values by row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 0.0), (2, 0.0), (3, 0.6), (4, 0.0), (5, 0.0), (6, 0.2), (7, 0.0)]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_miss_no_income.rdd.map(\n",
    "    lambda row: (row.id, sum([c == None for c in row])/len(row))\n",
    ").collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option 1) Drop rows that has more than 50% of missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+----+------+\n",
      "| id|weight|height| age|gender|\n",
      "+---+------+------+----+------+\n",
      "|  1| 143.5|   5.6|  28|     M|\n",
      "|  2| 167.2|   5.4|  45|     M|\n",
      "|  4| 144.5|   5.9|  33|     M|\n",
      "|  5| 133.2|   5.7|  54|     F|\n",
      "|  6| 124.1|   5.2|null|     F|\n",
      "|  7| 129.2|   5.3|  42|     M|\n",
      "+---+------+------+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_miss_no_income.rdd.filter(\n",
    "    lambda row: (sum([c == None for c in row])/len(row) < 0.5) \n",
    ").toDF().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option 2) Impute observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = df_miss_no_income.agg(*[\n",
    "    fn.mean(c).alias(c)\n",
    "    for c in df_miss_no_income.columns if c != 'gender'\n",
    "]).toPandas().to_dict('records')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 4.0,\n",
       " 'weight': 140.28333333333333,\n",
       " 'height': 5.471428571428571,\n",
       " 'age': 40.4}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "means['gender'] = 'missing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+------+---+-------+\n",
      "| id|            weight|height|age| gender|\n",
      "+---+------------------+------+---+-------+\n",
      "|  1|             143.5|   5.6| 28|      M|\n",
      "|  2|             167.2|   5.4| 45|      M|\n",
      "|  3|140.28333333333333|   5.2| 40|missing|\n",
      "|  4|             144.5|   5.9| 33|      M|\n",
      "|  5|             133.2|   5.7| 54|      F|\n",
      "|  6|             124.1|   5.2| 40|      F|\n",
      "|  7|             129.2|   5.3| 42|      M|\n",
      "+---+------------------+------+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_miss_no_income.fillna(means).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outliers are those observations that deviate significantly from the distribution of\n",
    "the rest of your sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The definitions of significance vary, but in the most general\n",
    "form, you can accept that there are no outliers if all the values are roughly within\n",
    "the <b>Q1−1.5IQR</b> and <b>Q3+1.5IQR</b> range, where IQR is the interquartile range; the IQR\n",
    "is defined as a difference between the upper- and lower-quartiles, that is, the 75th\n",
    "percentile (the Q3) and 25th percentile (the Q1), respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outliers = spark.createDataFrame([\n",
    " (1, 143.5, 5.3, 28),\n",
    " (2, 154.2, 5.5, 45),\n",
    " (3, 342.3, 5.1, 99),\n",
    " (4, 144.5, 5.5, 33),\n",
    " (5, 133.2, 5.4, 54),\n",
    " (6, 124.1, 5.1, 21),\n",
    " (7, 129.2, 5.3, 42),\n",
    " ], ['id', 'weight', 'height', 'age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['weight', 'height', 'age']\n",
    "bounds = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cols:\n",
    "    quantiles = df_outliers.approxQuantile(\n",
    "        col= col, probabilities = [0.25, 0.74],\n",
    "        relativeError = 0.05)\n",
    "    IQR = quantiles[1] - quantiles[0]\n",
    "    bounds[col] = [\n",
    "        quantiles[0] - 1.5 * IQR,\n",
    "        quantiles[1] + 1.5 * IQR\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weight': [91.69999999999999, 191.7],\n",
       " 'height': [4.499999999999999, 6.1000000000000005],\n",
       " 'age': [-11.0, 93.0]}"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flag outliers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+---+\n",
      "| id|weight|height|age|\n",
      "+---+------+------+---+\n",
      "|  1| 143.5|   5.3| 28|\n",
      "|  2| 154.2|   5.5| 45|\n",
      "|  3| 342.3|   5.1| 99|\n",
      "|  4| 144.5|   5.5| 33|\n",
      "|  5| 133.2|   5.4| 54|\n",
      "|  6| 124.1|   5.1| 21|\n",
      "|  7| 129.2|   5.3| 42|\n",
      "+---+------+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_outliers.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+--------+-----+\n",
      "| id|weight_o|height_o|age_o|\n",
      "+---+--------+--------+-----+\n",
      "|  1|   false|   false|false|\n",
      "|  2|   false|   false|false|\n",
      "|  3|    true|   false| true|\n",
      "|  4|   false|   false|false|\n",
      "|  5|   false|   false|false|\n",
      "|  6|   false|   false|false|\n",
      "|  7|   false|   false|false|\n",
      "+---+--------+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "outliers = df_outliers.select(*['id'] + [\n",
    " (\n",
    " (df_outliers[c] < bounds[c][0]) |\n",
    " (df_outliers[c] > bounds[c][1])\n",
    " ).alias(c + '_o') for c in cols\n",
    "])\n",
    "outliers.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing outliers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outliers = df_outliers.join(outliers, on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outliers = df_outliers.filter(\n",
    "    df_outliers['weight_o'] == False\n",
    ").filter(\n",
    "    df_outliers['height_o'] == False\n",
    ").filter(\n",
    "    df_outliers['age_o'] == False\n",
    ").select(*['id'] + cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+---+\n",
      "| id|weight|height|age|\n",
      "+---+------+------+---+\n",
      "|  7| 129.2|   5.3| 42|\n",
      "|  6| 124.1|   5.1| 21|\n",
      "|  5| 133.2|   5.4| 54|\n",
      "|  1| 143.5|   5.3| 28|\n",
      "|  2| 154.2|   5.5| 45|\n",
      "|  4| 144.5|   5.5| 33|\n",
      "+---+------+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_outliers.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting familiar with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_fraud = './data/ccFraud.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ccfraud = spark.read.csv(path= path_fraud,\n",
    "                           inferSchema = True,\n",
    "                           sep = ',',\n",
    "                           header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+-----+----------+-------+--------+------------+----------+---------+\n",
      "|custID|gender|state|cardholder|balance|numTrans|numIntlTrans|creditLine|fraudRisk|\n",
      "+------+------+-----+----------+-------+--------+------------+----------+---------+\n",
      "|     1|     1|   35|         1|   3000|       4|          14|         2|        0|\n",
      "|     2|     2|    2|         1|      0|       9|           0|        18|        0|\n",
      "|     3|     2|    2|         1|      0|      27|           9|        16|        0|\n",
      "|     4|     1|   15|         1|      0|      12|           0|         5|        0|\n",
      "|     5|     1|   46|         1|      0|      11|          16|         7|        0|\n",
      "+------+------+-----+----------+-------+--------+------------+----------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_ccfraud.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descriptive analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.types as typ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
